{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d36c492-a469-4aff-91f3-f07ed9f37061",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project aims to build a classification model that predicts wine quality based on its physicochemical properties using machine learning techniques. The dataset used is the Wine Quality dataset from the UCI Machine Learning Repository, which contains measurements like acidity, sugar content, sulfur dioxide levels, pH, and alcohol percentage for various red wine samples.\n",
    "\n",
    "Originally, the quality attribute is a numeric score ranging from 0 to 10, based on human sensory evaluations. However, since the scores are subjective, imbalanced, and ordered, we transform this into a binary classification task to simplify the modeling process.\n",
    "\n",
    "Using pandas.cut(), we divide the quality scores into two categories:\n",
    "- \"bad\": quality scores from 2 up to and including 6.5\n",
    "- \"good\": quality scores above 6.5 up to 8\n",
    "\n",
    "This transformation allows us to frame the problem as a binary classification task, where we train machine learning models to classify whether a wine is of good quality or not.\n",
    "\n",
    "The project applies several classification algorithms such as Decision Tree, Naive Bayes, and K-Nearest Neighbors (KNN). The performance of these models is evaluated using metrics like accuracy, precision, recall, F1-score, and ROC-AUC, allowing us to understand which physicochemical factors best predict wine quality and which model generalizes well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c840fba-4c1c-4215-bf0f-f63f4884d04a",
   "metadata": {},
   "source": [
    "# Importing required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45863956-65e3-4829-bafb-f73715205cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af523d9d-1bc4-4150-ae3a-aa750143a209",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d02062-750a-4926-948c-b9678f894304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('/home/jovyan/work/glow2025_final_project/data/winequality-red.csv')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c82c8-9b0d-46fe-b533-c476bd711a53",
   "metadata": {},
   "source": [
    "# Information on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c23f7-0b69-424a-909e-d686ae704e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86941b-8a38-40dd-b8c9-71027362fc26",
   "metadata": {},
   "source": [
    "### Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafadc76-a96e-4809-9235-26118dadbd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicates:\", wine.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04436cf-37e3-4f65-a100-0f8f18566ea4",
   "metadata": {},
   "source": [
    "Since duplicates exist, we will remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3bd90-97bb-4204-a35d-24729e670a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = wine.drop_duplicates()\n",
    "\n",
    "# Recheck for duplicates\n",
    "print(\"Duplicates:\", wine.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b892673-e175-4949-8b8f-2846c5de9c99",
   "metadata": {},
   "source": [
    "### Checking for outliers\n",
    "\n",
    "To ensure the quality of our dataset, we identify and remove outliers using the Interquartile Range (IQR) method. Outliers can skew the model's understanding of the data, especially for algorithms sensitive to distance or variance.\n",
    "\n",
    "We calculate:\n",
    "\n",
    "- Q1 (25th percentile)\n",
    "- Q3 (75th percentile)\n",
    "- IQR = Q3 - Q1\n",
    "\n",
    "Then we remove any rows where a feature value is below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76125e-7126-48e7-978f-94ec189ab139",
   "metadata": {},
   "source": [
    "Visualization Before Outliers Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923d45a-f008-4b8f-b6f3-f7b2370b9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(data=wine)\n",
    "plt.title(\"Boxplot for detecting outliers in wine dataset\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac9614-1bf7-45b6-8d8a-633b3a31fb05",
   "metadata": {},
   "source": [
    "### Outlier Removal Justification (Using 1.15 * IQR)\n",
    "\n",
    "Outliers in the dataset can negatively affect model performance, especially for distance-based models like K-Nearest Neighbors (KNN). The Interquartile Range (IQR) method is a common approach for detecting and removing outliers.\n",
    "\n",
    "By default, the standard IQR rule uses a multiplier of **1.5**:  \n",
    "**Outlier Threshold = [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR]**\n",
    "\n",
    "In this project, we use a slightly stricter threshold of **1.15**:  \n",
    "**Threshold = [Q1 - 1.15 * IQR, Q3 + 1.15 * IQR]**\n",
    "\n",
    "This slightly tighter bound removes more borderline outliers than the standard method, which is appropriate because:\n",
    "\n",
    "- The boxplots show many mild outliers in features like **free sulfur dioxide**, **residual sugar**, and **alcohol**.\n",
    "- Some of these values may represent noise or data-entry errors.\n",
    "- Removing them reduces skew and improves training signal quality.\n",
    "- It especially helps models sensitive to feature scales and extremes, such as **KNN**.\n",
    "\n",
    "Thus, using `1.15 * IQR` strikes a balance between cleaning the data and retaining useful samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d7319-cf4c-486b-8adb-8162517a18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers using the IQR method\n",
    "Q1 = wine.quantile(0.25)\n",
    "Q3 = wine.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Removing rows with any feature having an outlier\n",
    "wine = wine[~((wine < (Q1 - 1.15 * IQR)) | (wine > (Q3 + 1.15 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb8ab70-824f-443c-a9d7-51342e0c07ee",
   "metadata": {},
   "source": [
    "Visualization After Outliers Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1b4c3-006d-46a5-8420-db1e923b5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(data=wine)\n",
    "plt.title(\"Boxplot for detecting outliers in wine dataset\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2fcba3-0ea9-4266-9c4c-cb191f326712",
   "metadata": {},
   "source": [
    "# Column distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae0016-fcc0-4242-9a1a-6037d7879da0",
   "metadata": {},
   "source": [
    "To understand the relationship between physicochemical properties and wine quality, we use bar plots to visualize how different features vary across quality scores.\n",
    "\n",
    "These visualizations help us identify which features might be informative for predicting wine quality for example, does higher citric acid or fixed acidity correlate with better wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beef68-d3be-4511-9fcf-b2f004412de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', y='fixed acidity', x='quality', data=wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e7faf-6921-49d7-8f5c-6bae2f49fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', x = 'quality', y = 'citric acid', data = wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5b1ec-6dd4-4e00-bc80-63f375ce99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', x = 'quality', y = 'residual sugar', data = wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38f8f2-64a6-4ef8-8ce9-44776f109d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', x = 'quality', y = 'chlorides', data = wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6173c6-84f6-46f2-9619-1a01a83263a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', x = 'quality', y = 'free sulfur dioxide', data = wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c1d62-c9a8-4a1c-bc68-ed6cb53b46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', x = 'quality', y = 'total sulfur dioxide', data = wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ede28c-cc50-4794-b869-d64560c0db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', x = 'quality', y = 'sulphates', data = wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcade0d5-cae1-4e8c-8ecb-3054038f232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(hue='quality', x = 'quality', y = 'alcohol', data = wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cfb29f-9154-46ae-9127-7ff2d4207e7d",
   "metadata": {},
   "source": [
    "# Correlation Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16f7b8-b4f6-439e-8b38-4ef172e41078",
   "metadata": {},
   "source": [
    "This heatmap helps us see which features are strongly related to each other or to the target variable (`quality`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca12761-d894-4fcb-9e33-5652c2f353dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the correlation heatmap\n",
    "plt.figure(figsize=(12,8))  # Set figure size\n",
    "sns.heatmap(wine.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')  # Create heatmap\n",
    "plt.title(\"Correlation Between Features\")  # Add title\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28dba1-5953-466e-b4f9-b7186739ac52",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6524b113-abe1-45e3-a498-242eb91f4ec6",
   "metadata": {},
   "source": [
    "We are transforming the `quality` column from a multi-class numerical scale into a **binary classification** problem. \n",
    "\n",
    "The original `quality` scores range from 2 to 8, but for simplicity and clarity, we categorize them into:\n",
    "- `'bad'` for scores **≤ 6.5**\n",
    "- `'good'` for scores **> 6.5**\n",
    "\n",
    "This binning helps us build models that predict whether a wine is good or bad, rather than predicting an exact score.\n",
    "\n",
    "Then, we **encode** these categorical labels (`'bad'`, `'good'`) into numerical values (`0` and `1`) because machine learning models work with numbers.\n",
    "\n",
    "Finally, we use a **count plot** to visualize the distribution of these two new categories to understand class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73da8b6-7451-4cb0-9b99-8416be452dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges:\n",
    "# quality scores from 2 to 6.5 will be labeled 'bad', and 6.5 to 8 as 'good'\n",
    "bins = (2, 6.5, 8)\n",
    "\n",
    "# Define the corresponding labels for the bins\n",
    "group_names = ['bad', 'good']\n",
    "wine['quality'] = pd.cut(wine['quality'], bins = bins, labels = group_names)\n",
    "label_quality = LabelEncoder()\n",
    "\n",
    "#Bad becomes 0 and good becomes 1 \n",
    "wine['quality'] = label_quality.fit_transform(wine['quality'])\n",
    "\n",
    "sns.countplot(hue='quality', x='quality', data=wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498b3ed-6af5-435a-b82e-ad58991c71e7",
   "metadata": {},
   "source": [
    "Now that we've converted the wine quality into a binary label (bad or good), we're preparing the dataset for model training:\n",
    "\n",
    "1. **Separate features and labels:**  \n",
    "    We split the dataset into `X` (features) and `y` (target label, which is the encoded wine quality).  \n",
    "    This allows the model to learn patterns from input features to predict the output class.\n",
    "\n",
    "2. **Split the dataset:**  \n",
    "    We divide it into training and testing sets using an 80/20 split.  \n",
    "    The model will learn on the training set and be evaluated on the test set to measure performance on unseen data.\n",
    "\n",
    "3. **Normalize the feature values:**  \n",
    "    Using `StandardScaler`, we standardize the features so they all have the same scale (mean = 0, std = 1).  \n",
    "    This step is **especially important for K-Nearest Neighbors (KNN)**, since it relies on distance calculations.  \n",
    "    Even though Decision Tree and Naive Bayes don’t require feature scaling, we apply it here for consistency and to support models that do benefit from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c747ca0-3aa2-416a-b2c5-b8ab919b48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping a copy of the original feature data\n",
    "X_original = wine.drop('quality', axis=1).copy()\n",
    "\n",
    "# Use the copied data as feature set\n",
    "X = X_original  \n",
    "y = wine['quality']  # Target variable\n",
    "\n",
    "# Split data into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler for feature normalization\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)   # Fit + transform training data\n",
    "X_test_scaled = sc.transform(X_test)        # Transform test data only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee1011-4e36-4de4-9f78-065bb5b8cbb3",
   "metadata": {},
   "source": [
    "## Before vs After Normalization\n",
    "\n",
    "Before training our machine learning models, we normalize the features using **Z-score normalization** to ensure all variables are on the same scale.\n",
    "\n",
    "Why this matters:\n",
    "- Some features like **alcohol** or **sulfur dioxide** have values that are much higher than others like **pH**, which can skew results in models like **KNN** that are sensitive to magnitude.\n",
    "- **StandardScaler** transforms each feature to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "To visualize this transformation, we compare the original feature values to their normalized versions. This step helps confirm that normalization was applied correctly and highlights how much scaling affects the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18475a4c-0f29-4b5c-b63a-ee9cf8cb86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for visualization\n",
    "X_train_df_before = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_train_df_after = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_df_before = pd.DataFrame(X_test, columns=X.columns)\n",
    "X_test_df_after = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Visual comparison\n",
    "print(\"First 5 rows of training data (before normalization):\")\n",
    "display(X_train_df_before.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of training data (after normalization):\")\n",
    "display(X_train_df_after.head())\n",
    "\n",
    "print(\"First 5 rows of test data (before normalization):\")\n",
    "display(X_test_df_before.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of test data (after normalization):\")\n",
    "display(X_test_df_after.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c588f9-d595-47fa-8791-48d0ad6c4630",
   "metadata": {},
   "source": [
    "# Save features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1f16a-bece-4869-adf0-e2836bad59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(X_train_scaled, '/home/jovyan/work/glow2025_final_project/X_train.pkl')\n",
    "joblib.dump(X_test_scaled, '/home/jovyan/work/glow2025_final_project/X_test.pkl')\n",
    "joblib.dump(y_train, '/home/jovyan/work/glow2025_final_project/y_train.pkl')\n",
    "joblib.dump(y_test, '/home/jovyan/work/glow2025_final_project/y_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
